#!/usr/bin/env python3
"""
Automated Vulnerability Scanner

Comprehensive vulnerability scanning automation with Bandit, Safety, pip-audit integration.
Provides continuous security monitoring and automated reporting.
"""

import asyncio
import json
import logging
import schedule
import time
from datetime import datetime
from pathlib import Path
from typing import Dict, Any, List, Optional, Tuple
from dataclasses import dataclass

from security.quality_gates import SecurityQualityGates, SeverityLevel


logger = logging.getLogger(__name__)


@dataclass
class ScanSchedule:
    """Vulnerability scan schedule configuration."""
    name: str
    enabled: bool
    interval_hours: int
    scan_types: List[str]
    notify_on: List[str]  # ["critical", "high", "medium", "low"]
    auto_create_issues: bool = False


@dataclass
class VulnerabilityReport:
    """Vulnerability scan report."""
    scan_id: str
    timestamp: datetime
    scan_duration: float
    total_vulnerabilities: int
    by_severity: Dict[str, int]
    by_tool: Dict[str, int]
    new_vulnerabilities: int
    resolved_vulnerabilities: int
    scan_status: str
    recommendations: List[str]


class VulnerabilityScanner:
    """
    Automated vulnerability scanner with comprehensive reporting.
    
    Features:
    - Scheduled vulnerability scans
    - Automated security monitoring
    - Integration with multiple security tools
    - Trend analysis and reporting
    - GitHub integration for issue creation
    """
    
    def __init__(self, config_file: Optional[str] = None):
        """Initialize vulnerability scanner."""
        self.config = self._load_config(config_file)
        self.project_root = Path.cwd()
        
        # Create reports and data directories
        self.reports_dir = self.project_root / "security_reports"
        self.data_dir = self.project_root / ".security_data"
        self.reports_dir.mkdir(exist_ok=True)
        self.data_dir.mkdir(exist_ok=True)
        
        # Initialize quality gates
        self.quality_gates = SecurityQualityGates(config_file)
        
        # Scan history for trend analysis
        self.scan_history_file = self.data_dir / "scan_history.json"
        self.baseline_file = self.data_dir / "security_baseline.json"
        
        # Configure scan schedules
        self.scan_schedules = self._configure_scan_schedules()
        
        # Initialize monitoring
        self.monitoring_enabled = self.config.get("automation", {}).get("auto_create_issues", True)
        
        logger.info("VulnerabilityScanner initialized")
    
    def _load_config(self, config_file: Optional[str] = None) -> Dict[str, Any]:
        """Load vulnerability scanner configuration."""
        if config_file is None:
            config_file = "config/security_monitoring.json"
        
        try:
            with open(config_file, 'r') as f:
                config_data = json.load(f)
                return config_data.get("security_monitoring", {})
        except FileNotFoundError:
            logger.warning(f"Config file {config_file} not found, using defaults")
            return self._get_default_config()
        except json.JSONDecodeError as e:
            logger.error(f"Invalid JSON in config file {config_file}: {e}")
            return self._get_default_config()
    
    def _get_default_config(self) -> Dict[str, Any]:
        """Get default scanner configuration."""
        return {
            "monitoring_intervals": {
                "scan_interval_hours": 6,
                "dependency_check_hours": 24,
                "vulnerability_check_hours": 12,
                "quick_scan_minutes": 30
            },
            "automation": {
                "auto_create_issues": True,
                "auto_assign_security_issues": True
            },
            "thresholds": {
                "critical_threshold": 0,
                "high_threshold": 3,
                "medium_threshold": 15
            }
        }
    
    def _configure_scan_schedules(self) -> List[ScanSchedule]:
        """Configure vulnerability scan schedules."""
        intervals = self.config.get("monitoring_intervals", {})
        
        schedules = [
            ScanSchedule(
                name="comprehensive_scan",
                enabled=True,
                interval_hours=intervals.get("scan_interval_hours", 6),
                scan_types=["bandit", "safety", "pip_audit", "secrets", "custom"],
                notify_on=["critical", "high"],
                auto_create_issues=True
            ),
            ScanSchedule(
                name="dependency_scan",
                enabled=True,
                interval_hours=intervals.get("dependency_check_hours", 24),
                scan_types=["safety", "pip_audit"],
                notify_on=["critical", "high", "medium"],
                auto_create_issues=True
            ),
            ScanSchedule(
                name="quick_scan",
                enabled=True,
                interval_hours=intervals.get("quick_scan_minutes", 30) / 60,
                scan_types=["secrets", "bandit"],
                notify_on=["critical"],
                auto_create_issues=False
            )
        ]
        
        return schedules
    
    async def run_scheduled_scan(self, schedule: ScanSchedule) -> VulnerabilityReport:
        """Run a scheduled vulnerability scan."""
        scan_id = f"{schedule.name}_{datetime.now().strftime('%Y%m%d_%H%M%S')}"
        start_time = time.time()
        
        logger.info(f"Starting scheduled scan: {schedule.name} (ID: {scan_id})")
        
        # Load previous scan for comparison
        previous_vulnerabilities = await self._load_previous_scan_results()
        
        # Run quality gates for specified scan types
        results = {}
        
        if "bandit" in schedule.scan_types:
            results["bandit"] = await self.quality_gates._run_bandit_scan([str(self.project_root)])
        
        if "safety" in schedule.scan_types:
            results["safety"] = await self.quality_gates._run_safety_check([str(self.project_root)])
        
        if "pip_audit" in schedule.scan_types:
            results["pip_audit"] = await self.quality_gates._run_pip_audit([str(self.project_root)])
        
        if "secrets" in schedule.scan_types:
            results["secrets"] = await self.quality_gates._run_secrets_detection([str(self.project_root)])
        
        if "custom" in schedule.scan_types:
            results["custom"] = await self.quality_gates._run_custom_security_checks([str(self.project_root)])
        
        # Aggregate results
        all_vulnerabilities = []
        for result in results.values():
            all_vulnerabilities.extend(result.issues)
        
        # Calculate metrics
        by_severity = {
            "critical": sum(1 for v in all_vulnerabilities if v.severity == SeverityLevel.CRITICAL),
            "high": sum(1 for v in all_vulnerabilities if v.severity == SeverityLevel.HIGH),
            "medium": sum(1 for v in all_vulnerabilities if v.severity == SeverityLevel.MEDIUM),
            "low": sum(1 for v in all_vulnerabilities if v.severity == SeverityLevel.LOW)
        }
        
        by_tool = {}
        for result_name, result in results.items():
            by_tool[result_name] = len(result.issues)
        
        # Compare with previous scan
        new_vulnerabilities, resolved_vulnerabilities = await self._compare_with_previous(
            all_vulnerabilities, previous_vulnerabilities
        )
        
        # Determine scan status
        scan_status = "passed"
        if by_severity["critical"] > 0:
            scan_status = "critical_issues"
        elif by_severity["high"] > self.config.get("thresholds", {}).get("high_threshold", 3):
            scan_status = "high_issues"
        elif by_severity["medium"] > self.config.get("thresholds", {}).get("medium_threshold", 15):
            scan_status = "medium_issues"
        
        # Generate recommendations
        recommendations = await self._generate_recommendations(all_vulnerabilities, by_severity)
        
        # Create report
        report = VulnerabilityReport(
            scan_id=scan_id,
            timestamp=datetime.now(),
            scan_duration=time.time() - start_time,
            total_vulnerabilities=len(all_vulnerabilities),
            by_severity=by_severity,
            by_tool=by_tool,
            new_vulnerabilities=new_vulnerabilities,
            resolved_vulnerabilities=resolved_vulnerabilities,
            scan_status=scan_status,
            recommendations=recommendations
        )
        
        # Save scan results
        await self._save_scan_results(scan_id, all_vulnerabilities, report)
        
        # Handle notifications and issue creation
        await self._handle_scan_notifications(schedule, report, all_vulnerabilities)
        
        logger.info(f"Completed scan {scan_id}: {len(all_vulnerabilities)} vulnerabilities found")
        
        return report
    
    async def _load_previous_scan_results(self) -> List[Dict[str, Any]]:
        """Load previous scan results for comparison."""
        try:
            if self.scan_history_file.exists():
                with open(self.scan_history_file, 'r') as f:
                    history = json.load(f)
                    if history:
                        # Get most recent scan
                        latest_scan = max(history, key=lambda x: x.get("timestamp", ""))
                        return latest_scan.get("vulnerabilities", [])
        except Exception as e:
            logger.warning(f"Could not load previous scan results: {e}")
        
        return []
    
    async def _compare_with_previous(self, current_vulns: List[Any], 
                                   previous_vulns: List[Dict[str, Any]]) -> Tuple[int, int]:
        """Compare current vulnerabilities with previous scan."""
        # Create sets of vulnerability identifiers for comparison
        current_ids = set()
        for vuln in current_vulns:
            vuln_id = f"{vuln.file_path}:{vuln.line_number}:{vuln.rule_id}"
            current_ids.add(vuln_id)
        
        previous_ids = set()
        for vuln in previous_vulns:
            vuln_id = f"{vuln.get('file_path', '')}:{vuln.get('line_number', '')}:{vuln.get('rule_id', '')}"
            previous_ids.add(vuln_id)
        
        new_vulnerabilities = len(current_ids - previous_ids)
        resolved_vulnerabilities = len(previous_ids - current_ids)
        
        return new_vulnerabilities, resolved_vulnerabilities
    
    async def _generate_recommendations(self, vulnerabilities: List[Any], 
                                      by_severity: Dict[str, int]) -> List[str]:
        """Generate security recommendations based on scan results."""
        recommendations = []
        
        if by_severity["critical"] > 0:
            recommendations.append(f"URGENT: Fix {by_severity['critical']} critical security vulnerabilities immediately")
        
        if by_severity["high"] > 5:
            recommendations.append(f"High priority: Address {by_severity['high']} high-severity vulnerabilities")
        
        # Tool-specific recommendations
        tool_counts = {}
        for vuln in vulnerabilities:
            tool = getattr(vuln, 'tool', 'unknown')
            tool_counts[tool] = tool_counts.get(tool, 0) + 1
        
        if tool_counts.get("bandit", 0) > 10:
            recommendations.append("Consider implementing additional code security practices")
        
        if tool_counts.get("safety", 0) > 0 or tool_counts.get("pip_audit", 0) > 0:
            recommendations.append("Update vulnerable dependencies to secure versions")
        
        if tool_counts.get("custom_secrets_detection", 0) > 0:
            recommendations.append("Implement secrets management solution (e.g., HashiCorp Vault, AWS Secrets Manager)")
        
        # Trend-based recommendations
        scan_history = await self._get_scan_trend_analysis()
        if scan_history.get("increasing_trend", False):
            recommendations.append("Security issues are increasing - consider additional security training and reviews")
        
        return recommendations
    
    async def _save_scan_results(self, scan_id: str, vulnerabilities: List[Any], 
                                report: VulnerabilityReport) -> None:
        """Save scan results for historical analysis."""
        # Save detailed report
        report_data = {
            "scan_id": scan_id,
            "timestamp": report.timestamp.isoformat(),
            "scan_duration": report.scan_duration,
            "total_vulnerabilities": report.total_vulnerabilities,
            "by_severity": report.by_severity,
            "by_tool": report.by_tool,
            "new_vulnerabilities": report.new_vulnerabilities,
            "resolved_vulnerabilities": report.resolved_vulnerabilities,
            "scan_status": report.scan_status,
            "recommendations": report.recommendations,
            "vulnerabilities": [
                {
                    "issue_id": vuln.issue_id,
                    "severity": vuln.severity.value,
                    "title": vuln.title,
                    "description": vuln.description,
                    "file_path": vuln.file_path,
                    "line_number": vuln.line_number,
                    "rule_id": vuln.rule_id,
                    "tool": vuln.tool,
                    "remediation": vuln.remediation
                }
                for vuln in vulnerabilities
            ]
        }
        
        # Save individual report
        report_file = self.reports_dir / f"vulnerability_scan_{scan_id}.json"
        with open(report_file, 'w') as f:
            json.dump(report_data, f, indent=2)
        
        # Update scan history
        history = []
        if self.scan_history_file.exists():
            with open(self.scan_history_file, 'r') as f:
                history = json.load(f)
        
        history.append(report_data)
        
        # Keep only last 100 scans
        if len(history) > 100:
            history = history[-100:]
        
        with open(self.scan_history_file, 'w') as f:
            json.dump(history, f, indent=2)
        
        logger.info(f"Saved scan results: {report_file}")
    
    async def _handle_scan_notifications(self, schedule: ScanSchedule, 
                                       report: VulnerabilityReport,
                                       vulnerabilities: List[Any]) -> None:
        """Handle notifications and issue creation based on scan results."""
        # Check if notification is needed
        should_notify = False
        notification_level = ""
        
        if report.by_severity["critical"] > 0 and "critical" in schedule.notify_on:
            should_notify = True
            notification_level = "critical"
        elif report.by_severity["high"] > 0 and "high" in schedule.notify_on:
            should_notify = True
            notification_level = "high"
        elif report.by_severity["medium"] > 0 and "medium" in schedule.notify_on:
            should_notify = True
            notification_level = "medium"
        elif report.by_severity["low"] > 0 and "low" in schedule.notify_on:
            should_notify = True
            notification_level = "low"
        
        if should_notify:
            await self._send_notifications(report, notification_level)
        
        # Create GitHub issues if configured
        if schedule.auto_create_issues and self.monitoring_enabled:
            await self._create_github_issues(vulnerabilities, report)
    
    async def _send_notifications(self, report: VulnerabilityReport, level: str) -> None:
        """Send notifications about scan results."""
        # Console notification
        if self.config.get("alerting", {}).get("console_alerts", True):
            print(f"\nüö® SECURITY ALERT ({level.upper()})")
            print(f"Scan ID: {report.scan_id}")
            print(f"Critical: {report.by_severity['critical']}")
            print(f"High: {report.by_severity['high']}")
            print(f"Medium: {report.by_severity['medium']}")
            print(f"Total: {report.total_vulnerabilities}")
            
            if report.recommendations:
                print("\nRecommendations:")
                for rec in report.recommendations[:3]:
                    print(f"  ‚Ä¢ {rec}")
        
        # GitHub alerts (if configured)
        if self.config.get("alerting", {}).get("github_alerts", False):
            await self._create_github_alert(report, level)
        
        # Additional notification methods can be added here
        logger.info(f"Sent {level} security notification for scan {report.scan_id}")
    
    async def _create_github_issues(self, vulnerabilities: List[Any], 
                                   report: VulnerabilityReport) -> None:
        """Create GitHub issues for critical vulnerabilities."""
        critical_vulns = [v for v in vulnerabilities if v.severity == SeverityLevel.CRITICAL]
        high_vulns = [v for v in vulnerabilities if v.severity == SeverityLevel.HIGH]
        
        # Create issues for critical vulnerabilities
        for vuln in critical_vulns[:5]:  # Limit to 5 issues per scan
            await self._create_single_github_issue(vuln, "critical")
        
        # Create summary issue for high vulnerabilities if many exist
        if len(high_vulns) > 3:
            await self._create_summary_github_issue(high_vulns, report)
    
    async def _create_single_github_issue(self, vulnerability: Any, priority: str) -> None:
        """Create a single GitHub issue for a vulnerability."""
        try:
            # This would integrate with GitHub API
            issue_title = f"üö® Security: {vulnerability.title}"
            issue_body = f"""
**Security Vulnerability Detected**

**Severity:** {vulnerability.severity.value.upper()}
**File:** {vulnerability.file_path}
**Line:** {vulnerability.line_number or 'N/A'}
**Tool:** {vulnerability.tool}

**Description:**
{vulnerability.description}

**Remediation:**
{vulnerability.remediation or 'See security documentation for guidance'}

**Rule ID:** {vulnerability.rule_id}

---
*This issue was automatically created by the Security Quality Gates system.*
*Scan ID: {datetime.now().strftime('%Y%m%d_%H%M%S')}*
"""
            
            # For now, just log the issue creation
            logger.info(f"Would create GitHub issue: {issue_title}")
            
        except Exception as e:
            logger.error(f"Failed to create GitHub issue: {e}")
    
    async def _create_summary_github_issue(self, vulnerabilities: List[Any], 
                                         report: VulnerabilityReport) -> None:
        """Create a summary GitHub issue for multiple vulnerabilities."""
        try:
            issue_title = f"üö® Security Summary: {len(vulnerabilities)} High-Severity Issues"
            issue_body = f"""
**Security Vulnerability Summary**

**Scan ID:** {report.scan_id}
**Total Issues:** {report.total_vulnerabilities}
**High Severity Issues:** {len(vulnerabilities)}

**Summary by File:**
"""
            
            # Group by file
            by_file = {}
            for vuln in vulnerabilities:
                file_path = vuln.file_path
                if file_path not in by_file:
                    by_file[file_path] = []
                by_file[file_path].append(vuln)
            
            for file_path, file_vulns in by_file.items():
                issue_body += f"\n**{file_path}:** {len(file_vulns)} issues"
                for vuln in file_vulns[:3]:  # Show first 3 per file
                    issue_body += f"\n  - Line {vuln.line_number or 'N/A'}: {vuln.title}"
                if len(file_vulns) > 3:
                    issue_body += f"\n  - ... and {len(file_vulns) - 3} more"
            
            issue_body += """

**Recommendations:**
"""
            for rec in report.recommendations:
                issue_body += f"- {rec}\n"
            
            issue_body += """
---
*This summary was automatically created by the Security Quality Gates system.*
"""
            
            logger.info(f"Would create GitHub summary issue: {issue_title}")
            
        except Exception as e:
            logger.error(f"Failed to create GitHub summary issue: {e}")
    
    async def _get_scan_trend_analysis(self) -> Dict[str, Any]:
        """Analyze scan trends over time."""
        try:
            if not self.scan_history_file.exists():
                return {"increasing_trend": False, "data_points": 0}
            
            with open(self.scan_history_file, 'r') as f:
                history = json.load(f)
            
            if len(history) < 3:
                return {"increasing_trend": False, "data_points": len(history)}
            
            # Analyze last 10 scans
            recent_scans = history[-10:]
            vulnerability_counts = [scan.get("total_vulnerabilities", 0) for scan in recent_scans]
            
            # Simple trend analysis
            if len(vulnerability_counts) >= 3:
                recent_avg = sum(vulnerability_counts[-3:]) / 3
                older_avg = sum(vulnerability_counts[:-3]) / len(vulnerability_counts[:-3])
                increasing_trend = recent_avg > older_avg * 1.2  # 20% increase threshold
            else:
                increasing_trend = False
            
            return {
                "increasing_trend": increasing_trend,
                "data_points": len(vulnerability_counts),
                "recent_average": recent_avg if len(vulnerability_counts) >= 3 else 0,
                "trend_data": vulnerability_counts
            }
            
        except Exception as e:
            logger.warning(f"Could not analyze scan trends: {e}")
            return {"increasing_trend": False, "data_points": 0}
    
    def start_scheduled_monitoring(self) -> None:
        """Start scheduled vulnerability monitoring."""
        logger.info("Starting scheduled vulnerability monitoring")
        
        # Schedule scans based on configuration
        for scan_schedule in self.scan_schedules:
            if scan_schedule.enabled:
                if scan_schedule.interval_hours >= 1:
                    schedule.every(int(scan_schedule.interval_hours)).hours.do(
                        self._run_scheduled_scan_sync, scan_schedule
                    )
                else:
                    # Handle sub-hour intervals
                    minutes = int(scan_schedule.interval_hours * 60)
                    schedule.every(minutes).minutes.do(
                        self._run_scheduled_scan_sync, scan_schedule
                    )
                
                logger.info(f"Scheduled {scan_schedule.name} every {scan_schedule.interval_hours}h")
        
        # Run monitoring loop
        print("üîí Security monitoring started")
        print("Press Ctrl+C to stop")
        
        try:
            while True:
                schedule.run_pending()
                time.sleep(60)  # Check every minute
        except KeyboardInterrupt:
            print("\nüõë Security monitoring stopped")
    
    def _run_scheduled_scan_sync(self, scan_schedule: ScanSchedule) -> None:
        """Synchronous wrapper for scheduled scan execution."""
        try:
            asyncio.run(self.run_scheduled_scan(scan_schedule))
        except Exception as e:
            logger.error(f"Scheduled scan {scan_schedule.name} failed: {e}")
    
    async def run_manual_scan(self, scan_types: Optional[List[str]] = None) -> VulnerabilityReport:
        """Run a manual vulnerability scan."""
        if scan_types is None:
            scan_types = ["bandit", "safety", "pip_audit", "secrets", "custom"]
        
        manual_schedule = ScanSchedule(
            name="manual_scan",
            enabled=True,
            interval_hours=0,
            scan_types=scan_types,
            notify_on=["critical", "high", "medium"],
            auto_create_issues=False
        )
        
        return await self.run_scheduled_scan(manual_schedule)
    
    async def generate_security_dashboard(self) -> Dict[str, Any]:
        """Generate security dashboard data."""
        try:
            # Load scan history
            history = []
            if self.scan_history_file.exists():
                with open(self.scan_history_file, 'r') as f:
                    history = json.load(f)
            
            # Calculate dashboard metrics
            if not history:
                return {"status": "no_data", "message": "No scan history available"}
            
            latest_scan = history[-1] if history else None
            trend_analysis = await self._get_scan_trend_analysis()
            
            # Calculate summary statistics
            total_scans = len(history)
            avg_vulnerabilities = sum(scan.get("total_vulnerabilities", 0) for scan in history) / total_scans if total_scans > 0 else 0
            
            dashboard = {
                "status": "active",
                "last_updated": datetime.now().isoformat(),
                "summary": {
                    "total_scans": total_scans,
                    "latest_scan": latest_scan,
                    "average_vulnerabilities": round(avg_vulnerabilities, 1),
                    "trend_analysis": trend_analysis
                },
                "recent_scans": history[-10:] if len(history) > 10 else history,
                "security_metrics": {
                    "critical_issues_last_30_days": sum(
                        scan.get("by_severity", {}).get("critical", 0) 
                        for scan in history[-30:] if history
                    ),
                    "high_issues_last_30_days": sum(
                        scan.get("by_severity", {}).get("high", 0) 
                        for scan in history[-30:] if history
                    ),
                    "scan_frequency": "Every 6 hours" if self.scan_schedules else "Manual only"
                }
            }
            
            return dashboard
            
        except Exception as e:
            logger.error(f"Failed to generate security dashboard: {e}")
            return {"status": "error", "message": str(e)}


# CLI interface
if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="Automated Vulnerability Scanner")
    parser.add_argument("--scan", action="store_true", help="Run immediate scan")
    parser.add_argument("--monitor", action="store_true", help="Start continuous monitoring")
    parser.add_argument("--dashboard", action="store_true", help="Generate security dashboard")
    parser.add_argument("--config", help="Configuration file path")
    parser.add_argument("--scan-types", nargs="+", 
                       choices=["bandit", "safety", "pip_audit", "secrets", "custom"],
                       help="Specific scan types to run")
    
    args = parser.parse_args()
    
    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )
    
    async def main():
        scanner = VulnerabilityScanner(args.config)
        
        if args.scan:
            print("üîç Running vulnerability scan...")
            report = await scanner.run_manual_scan(args.scan_types)
            print(f"\nüìä Scan completed: {report.total_vulnerabilities} vulnerabilities found")
            print(f"   Critical: {report.by_severity['critical']}")
            print(f"   High: {report.by_severity['high']}")
            print(f"   Medium: {report.by_severity['medium']}")
            print(f"   Low: {report.by_severity['low']}")
            
        elif args.dashboard:
            print("üìà Generating security dashboard...")
            dashboard = await scanner.generate_security_dashboard()
            print(json.dumps(dashboard, indent=2))
            
        elif args.monitor:
            scanner.start_scheduled_monitoring()
            
        else:
            parser.print_help()
    
    if args.monitor:
        # For monitoring, run in sync mode
        scanner = VulnerabilityScanner(args.config)
        scanner.start_scheduled_monitoring()
    else:
        asyncio.run(main())